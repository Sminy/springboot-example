## Java基础知识

### 1 数据结构

#### 1.1 HashMap简介

| jdk7     | jdk8                             |                                                              |
| :------- | :------------------------------- | ------------------------------------------------------------ |
| 实现方式 | 数组+链表                        | 数组+链表/红黑树，其中数组长度>64，链表长度>8时，链表转换为红黑树 |
| 数组     | new hashmap() 时创建长度16的数组 | new的时候不创建而是采用懒汉式的方式首次调用put时创建         |
| 链表     | 采用头插法插入新元素             | 采用尾插法                                                   |

**参数说明：**

- DEFAULT_INITIAL_CAPACITY: 默认容量：16
- DAFAULT_LOAD_FACTOR: 默认加载因子：0.75，反应数组的密度
- threshold: 扩容的临界值， = 容量*填充因子，16*0.75=12，当数组有12个元素时发生第一次扩容
- TREEIFY_THRESHOLD: Bucket中链表长度大于该默认值时==有可能==转换为红黑树，值为8
- MIN_TREEIFY_CAPACITY: 桶中的node被树化时最小的hash表容量，值为64

#### 1.2 HashMap底层原理

HashMap本质上是使用的链地址法的散列表的数据结构，这种数据结构很好的解决了HashMap的key不重复的特点，不同于其他的查找算法是直接比较关键字的，散列表将地址和关键字通过hash算法建立了映射使查找效率提升到了*O*(1)。
jdk1.8采用底层是16的数组+链表/红黑树实现的，线程不安全的，key和value都可以为null，扩容为原来的2倍，数组长度要是2的n次幂，是因为计算出哈希值以后是通过&arr.len-1的方式来计算数组下标。当数组长度大于64，链表长度大于8的时候，链表会转换为红黑树。

#### 1.3 为什么要转换为红黑树

转换为红黑树也是出于提高查找效率的考量。因为随着插入数据的增多，hash碰撞也会更频繁，导致链表的长度会增加，使查找时间复杂度提高到*O*(*N*)，这时候就想到了用二叉查找树，由于二叉查找树左子树都小于根节点都小于右子树，这就使得二叉查找树的查找时间复杂度一般情况下会等于折半查找的效率logN，这里你可能就有疑问为啥不直接用折半查找呢，因为折半查找是基于数组的，删除、插入操作复杂度为*O*(*N*)而二叉树是基于链表复杂度为logN，我们在继续说回来，二叉查找树一般情况是logN，但是最坏情况下会导致二叉排序树变为单向链表使查找复杂度变为*O*(*N*),所以就想到了用平衡二叉树，平衡二叉树的左子树和右子树高度绝对值相差不超过1，使得查找复杂度都是logN，但是在插入和删除的时候要进行大量旋转使得插入删除后的树还是平衡二叉树，而红黑树放弃了完全平衡是自平衡或者部分平衡的二叉树，通过变色来实现更少的旋转来保持红黑树的定义。所以当频繁的插入和删除操作，切记放弃AVL树，选择性能更好的红黑树；涉及的插入和删除操作并不频繁，而是查找操作相对更频繁，那么就优先选择 AVL 树进行实现。

#### 1.4 介绍下红黑树

**定义：**

1. 每个结点要么是红色要是么黑色
2. 根节点是黑色
3. 如果一个结点是红色，则它的两个孩子都是黑色，即不能同时出现两个连续红结点
4. 每个叶子结点都是黑色
5. 对于每个结点，从该结点到其子孙结点的所有路径上包含相同数目的黑结点

其中第5点事最难符合的，所以程序实现红黑树时，每次插入新节点时，默认插入红结点，以满足第5条定义。第5条定义同时保证了，在去除掉红黑树的所有红结点之后，所有黑结点是平衡的。

**好处：**

1. 通过变色可以减少树的旋转操作来满足一棵红黑树
2. 有定理证明红黑树的查找，插入，删除操作的时间复杂度都是*O*(*l**o**g**N*)
3. 程序实现时，可以通过红黑树的定义归纳总结出该节点本身，父节点，祖父结点的变化规律，从而实现一棵红黑树的构建。

#### 1.5 HashMap和Hashtable区别

|              | HashMap      | Hashtable，注意t是小写，原始的KV键值对实现方式 |
| :----------- | :----------- | :--------------------------------------------- |
| 线程是否安全 | 线程不安全   | 线程安全，通过sychronized修饰方法实现          |
| key和value   | 都可以为null | 都不可以null                                   |
| 数组扩容     | 原来的2倍    | 原来的2倍                                      |

Properties是Hashtable的子类。

#### 1.6 LinkedHashMap底层原理

与HashMap相同，因为继承于HashMap。区别在于提供了Entry替代Node，多了一个前驱和后继指针，用来顺序输出。

#### 1.7 讲一下ConcurrentHashMap

ConcurrentHashMap是线程安全的，用来解决多线程情况时使用。jdk7底层使用的是分段锁。主要思想是通过细粒度锁来实现高并发读取修改map。默认情况下分16个段，也就是支持16个线程并发访问。jdk8使用的 Synchronized锁加CAS的机制，put元素时先cas进行put，Synchronized用来保底。

#### 1.8 说一下List

List特点：有序可重复

|              | ArrayList  | Vector（原始的数组集合类实现方式）    |
| :----------- | :--------- | :------------------------------------ |
| 并发是否安全 | 线程不安全 | 线程安全，通过sychronized修饰方法实现 |
| 扩容         | 扩容1.5倍  | 扩容2倍                               |
| 数组初始长度 | 10         | 10                                    |

LinkedList:双向链表实现，线程不安全，插入删除快，查找慢；ArrayList因下表查找快，插入删除因移动元素慢

#### 1.9 说一下Set

Set特点：无需不可重复

|                    | HashSet                                                      | LinkedSet                                                    | TreeSet                                                  |
| :----------------- | :----------------------------------------------------------- | :----------------------------------------------------------- | :------------------------------------------------------- |
| 实现方式           | 链地址法的散列表，底层是HashMap实现，利用map的key存储，value是一个static的object对象 | 散列表+额外的两个指针，指针用来记录前驱和后继，可以按插入的顺序输出元素； | 底层是红黑树                                             |
| 判断结点相同的方式 | 用hashcode和equals方法判断结点相同                           | 用hashcode和equals方法判断结点相同                           | 用comparable或comparator判断结点相同，只能排序同类型数据 |

### 2 多线程

**线程状态切换图：**

![图片](https://mmbiz.qpic.cn/mmbiz_png/DsvqQRrhuDhwPqmJVicgb1VfU9ayqVZSL4fjojreYCdcx2DQtzWTpPyjLicVdbsF6qtbWpUte8LEtpvoRdfwSibibg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**并发编程的三大特性:**（《参见Java内存模型》）

1. 可见性
2. 原子性
3. 有序性

#### 2.1 讲一下AQS

AQS是juc下面的包，是java并发编程的基石框架，他是用来构建锁的一个框架，像ReentrantLock、CountDownLatch、Semaphore等都是基于他来实现的。他实现的话主要用到的volatile的一个int型state来实现是共享锁还是独占锁，一个双向链表的队列+CAS来实现是公平锁还是非公平锁。公平锁的话在抢占资源的时候会去判断队列中是否有其他等待线程有的话会加入队列排队，非公平锁的话会直接用cas去抢占锁不看队列，能抢到的话就直接用，不能的话再去走公平锁的流程。

#### 2.2 讲一下CAS

CAS是比较并交换，他本质是乐观锁的思想，乐观锁就是很乐观，认为每次去数据时都不会被修改，不会上锁，在更新时去判断有没有被更新过，只有提交版本号大于当前版本号才会执行。CAS的实现也是这样的，我们知道JMM-java内存模型，共享变量在主内存中（类似于堆），线程在操作共享变量时会拷贝一份到自己的工作内存中，cas就是我不上锁，直接操作副本变量，在更新到主内存是在判断主内存的值是否和当时拷贝的值是否一致，一致的话就更新，不一致的话，就重新走这个过程。底层调用的是unsafe类。

#### 2.3 CAS的缺点

1. 循环时间长开销大，但提高了并发量和吞吐率
2. 只能保证一个共享变量的原子操作
3. ABA问题

#### 2.4 如何解决ABA问题

通过增加版本号或者时间戳的方式。我们工作中经常用的是atomic包下的AtomicStampedReference。

#### 2.5 讲一下ConutDownLatch、CyclicBarrier、Semaphore

这三个锁都是基于aqs实现的，是juc给我们提供的常用辅助类，都是用来解决线程执行顺序的问题。

- ConutDownLatch倒计时器，做减法，主要用来解决当一个线程要等待其他线程结果时使用，jdk8以后我们习惯使用**CompletableFuture.allof**来实现。
- CyclicBarrier循环栅栏，设计理念和倒计时器相反，是做加法，例如人到齐了开会。
- Semaphore信号量，共享锁的概念，可以用来限流。



Demo: 我们在处理业务时，有时会有多任务异步处理，同步返回结果的情况，在java中，我们可以使用CompletableFuture的allOf方法来实现多实例的同时返回。

```
   public void futureTest() {
        CompletableFuture<String> future1 = CompletableFuture.supplyAsync(() -> {
            try {
                Thread.sleep(10);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.println("future1 finished!");
            return "future1 finished!";
        });
        CompletableFuture<String> future2 = CompletableFuture.supplyAsync(() -> {
            System.out.println("future2 finished!");
            return "future2 finished!";
        });
        CompletableFuture<Void> combindFuture = CompletableFuture.allOf(future1, future2);
        try {
            combindFuture.get();
        } catch (InterruptedException e) {
            e.printStackTrace();
        } catch (ExecutionException e) {
            e.printStackTrace();
        }
        System.out.println("future1: " + future1.isDone() + " future2: " + future2.isDone());
    }
    
    
    
    // 	异步编程，不想阻塞线程的话，可以使用thenAccpt、thenApply、thenRun，future结束后，执行异步方法
```



#### 2.6 谈一下volatile

volatile是java线程同步的轻量级实现。他满足可见性，禁止指令重排（有序性），不满足原子性。可用使用atomic类来解决原子性问题。

#### 2.7 volatile和synchronized的区别

1. volatile主要用于解决多线程之间可见，synchronized主要解决同步
2. volatile是轻量级的，没有加锁，synchronized加锁
3. volatile只能用于变量，synchronized可以用于代码块和方法
4. volatile不保证原子性，synchronized都能保证

#### 2.8 多线程实现的方式

1. 继承Thread
2. 实现Runnable
3. 实现Callable，配合FutureTask
4. 线程池

#### 2.9 线程池的优点

1. 线程复用，不用频繁创建线程，提高资源利用率
2. 控制并发数
3. 便于管理线程

#### 2.10 创建线程池的方式



Executors工具类提供了三种方式，但是本质上都是操控ThreadPoolExecutor

1. newFixedThreadPool,固定线程数
2. newSingleThreadPool，单一线程数
3. newCachedThreadPool,可扩容伸缩的线程池

备注：阿里不建议使用Excutors创建线程。

Demo:

```
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue<Runnable> workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler)
```

构造函数参数说明：

> - corePoolSize => 线程池核心线程数量
> - maximumPoolSize => 线程池最大数量
> - keepAliveTime => 空闲线程存活时间
> - unit => 时间单位
> - workQueue => 线程池所使用的缓冲队列
> - threadFactory => 线程池创建线程使用的工厂
> - handler => 线程池对拒绝任务的处理策略

#### 2.11 使用哪一种来创建线程

使用自定义的线程池来创建线程。原因如下，我们看这三种方式的底层源码会发现
newFixedThreadPool和newSingleThreadPool使用的阻塞队列的长度为整形的最大值，这样在高并发的情况下会导致大量请求挤压，而newCachedThreadPool的最大线程数的参数是整形的最大值，这也会导致创建大量线程而引发OOM。所以我们使用自定义的线程池。

#### 2.12 线程池的参数

线程池有7个参数

1. 核心线程数
2. 最大线程数
3. 空闲线程存活时间
4. 时间单位
5. 阻塞队列
6. 线程工厂
7. 拒绝策略

#### 2.13 线程池的执行过程

**线程池的4个组件：**

1. 线程池管理器
2. 工作线程
3. 任务接口
4. 任务队列

**执行过程：**

1. 线程池分配线程时首先会去看核心线程数是否为满，没满就分配
2. 核心线程数满就会将请求加入阻塞队列
3. 阻塞队列满了，就会扩线程数到最大线程数，然后将阻塞队列中的请求，按顺序分配线程
4. 最大线程数满了且阻塞队列满了就会执行拒绝策略来限流
5. 当流量下来之后会进行缩容到核心线程数

#### 2.14 线程池的拒绝策略有哪些

线程池默认的有4个策略

1. AbortPolicy（默认），直接抛出RejectedExecutionException异常，阻止正常运行
2. DiscardPolicy，抛弃但不报错
3. DiscardOldestPolicy，抛弃等待最久的请求
4. CallerRunsPolicy，回退给调用者执行

#### 2.15 自定义线程池参数怎么设置的

最大线程数的设置，如果是cpu密集型，阻塞少，就设置为cpu核数+1，IO密集型，阻塞多，就设置为2*cpu核数，当然可以把这些参数设置为配置，听说美团就是这样干的。
获取机器核数：Runtime.getRuntime().availableProcessors()

#### 2.16 讲一讲LockSupport

LockSupport我们经常用来阻塞和唤醒线程使用，他是通过发放许可证的方式来运行的，而且许可证的最大值是1。经常用的方法是park和unpark分别是阻塞和唤醒。和wait/notify，await/signal不同的有两点：

1. 他们不需要再同步代码块中
2. 由于是发放许可证的方式，不需要阻塞在前，唤醒在后

synchronized和lock等待唤醒通知的约束：

1. 线程先要获得并持有锁，必须在锁块中
2. 必须要先等待后唤醒

#### 2.17 讲一下ThreadLocal

ThreadLocal本质上是用来创建线程的局部变量来达到高并发的一种手段。这里线程的局部变量和方法的局部变量概念是不一样的，因为我们知道线程的虚拟机栈是私有的，方法是栈帧，方法出栈之后，方法的局部变量就回收了。但是ThreadLocal创建的局部变量不是这样的，他的消亡要么是主动移除要么是随着线程消亡而消亡，这样也减少了线程内部多个方法直接的公共变量的传递，起到了一定程度上的解耦。

#### 2.18 ThreadLocal的原理

ThreadLoal底层是通过ThreadLoalMap实现的。jdk7以前是每一个threadLocal都会创建一个map，key是线程的引用；jdk8以后是每一个线程内部有一个localmap的变量，key的值是threadlocal的引用。threadlocalmap采用的线程探测法来处理hash冲突的。

#### 2.19 ThrealLocal为什么使用弱引用

首先ThreadLocal被回收的时候，要么是调用移除方法，要么是线程销毁，所以使用弱引用并不能保证不会引起OOM，但是会增加一层保障。我们知道弱引用是发生gc的时候，如果没有gcroot的引用链指向他就会回收掉，就会导致threadlocalmap里面key为null，但是value值不会变，如果value值很大时，OOM还是会发生。多的一层保障是什么呢，就是在threadlocal在get/putEntry方法调用时，会去将key为null 的value也置为null。

#### 2.20 Synchronized和ThreadLocal的区别

1. synchronized是一种时间换空间的思想，只提供一份变量。
2. threadlocal是一种空间换时间的思想，每个线程提供一份变量副本
3. synchronized多个线程之间访问同步资源
4. threadlocal是多个线程之间数据隔离

#### 2.21 单例的实现方式

1. 饿汉式，static直接new实例
2. 懒汉式，doubleCheck+volatile，volatile禁止指令重排防止出现在对象没初始化的情况下，this指针逃逸问题。
3. 枚举
4. 静态内部类，随着实例化而加载。

#### 2.22 List、Set、Map安全问题

- List

- - ArrayList-->Vector-->Collections.synchronizedList()

    -->CopyOnWriterArrayList

  - CopyOnWriterArrayList采用读写分离的思想。写时复制：写的时候加锁，复制一份，数组长度+1，指向新数组，解锁；读的时候不加锁

- Set

- - HashSet--->Collections.synchronizedList()--->CopyOnWriterArraySet，底层使用CopyOnWriterArrayList实现

- Map

- - HashMap--->Hashtable--->ConcurrentHashMap

#### 2.23 sychronized 可重入怎么实现的

每个锁关联一个线程持有者和一个计数器。当计数器为0时，表示该锁没有被任务线程持有。当一个线程请求成功后，JVM会记下持有锁的线程，并将计数器计为1；其他线程请求该锁，则必须等待；而持有锁的线程如果再次请求这个锁则计数器会递增；当线程退出一个synchronized时，计数器会递减，如果计数器为0，则释放该锁。

#### 2.24 JDK1.6后sychronized 的优化

JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。

锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。

#### 2.25 死锁

**死锁发生条件：**

- 互斥条件

- 不可剥夺条件，解决办法：请求被拒绝则释放占有资源

- 请求保持条件，解决办法：

- - 1，一次性分配线程需要的所有锁
  - 2，请求新资源时释放老资源

- 循环等待条件

**只要系统发生死锁，这4个条件必然成立，而只要上述条件之一不满足就不会发生死锁。**